{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b2f336-c97c-4eb8-a72d-6d686578282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c3d6a-d705-4f74-bb6e-0ab15e91629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e91e85-de23-42c7-9724-706eb5f49434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba6b76a-a07a-46cc-aebb-1bff341250b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "\n",
    "folder_path = r\"C:\\Users\\aparn\\Box\\Data (Matthew Rizzo)\\DataAnalysis\\FormattingQAChecks\\ActiGraph_FormattingQAChecks\\ActiGraph_FormatQA_Data\\Sleep\\Data\\Sleep_Formatted_Centrepoint\\CleanSingleNightSleep_Formatted_Centrepoint\"\n",
    "\n",
    "print(\"exists:\", os.path.exists(folder_path))\n",
    "print(\"isdir:\", os.path.isdir(folder_path))\n",
    "\n",
    "# sometimes a short pause helps if Box is re-syncing\n",
    "time.sleep(2)\n",
    "print(\"exists after 2s:\", os.path.exists(folder_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa53b6e-c68b-43cc-9187-2233222d6e36",
   "metadata": {},
   "source": [
    "## Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271df2cd-1fca-462e-8da3-5dd86501c313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "\n",
    "# Define the path to the folder\n",
    "folder_path = r\"C:\\Users\\aparn\\Box\\Data (Matthew Rizzo)\\DataAnalysis\\FormattingQAChecks\\ActiGraph_FormattingQAChecks\\ActiGraph_FormatQA_Data\\Sleep\\Data\\Sleep_Formatted_Centrepoint\\CleanSingleNightSleep_Formatted_Centrepoint\"\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Function to read each CSV file\n",
    "def read_csv(file):\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# Print number of CSV files to check if it's large\n",
    "print(f\"Number of CSV files: {len(csv_files)}\")\n",
    "\n",
    "# Use ThreadPoolExecutor to read the files in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Map the read_csv function to each file in csv_files\n",
    "    dfs = list(executor.map(read_csv, csv_files))\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "sleep_df = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0493c5d8-6160-4cde-bcc9-655ca2725a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sleep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68201375-4517-4546-a8c0-3d081b375a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07599d8c-c2ac-46e0-a6c4-07af7c20c15e",
   "metadata": {},
   "source": [
    "# Count the imputed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a6514a-e2b4-49cd-8c81-04c06d6bb1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of True values in 'sleep_median' column\n",
    "sleep_median_true_count = sleep_df[sleep_df['sleep_median'] == True].shape[0]\n",
    "\n",
    "# Print the result\n",
    "print(f\"The count of sleep_median == True is: {sleep_median_true_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491927eb-6338-49a3-9019-082589532151",
   "metadata": {},
   "source": [
    "## Remove datapoints where Sleep_wear==false\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682bcbd8-793e-4ac4-a390-0e3a292ae60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of 'False' values in 'sleep_wear' for each unique 'subj'\n",
    "false_counts = sleep_df.groupby('subj')['sleep_wear'].apply(lambda x: (x == False).sum()).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "false_counts.columns = ['subj', 'false_count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b917c65-d977-4832-9758-5fd5b9f94071",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c8a8ec-2d1b-443f-b657-9c23db3ca01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of the 'false_count' column\n",
    "total_false_count = false_counts['false_count'].sum()\n",
    "\n",
    "# Display the result\n",
    "print(total_false_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf285dfd-e590-4ca5-bba5-34dd82238886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'sleep_wear' is False\n",
    "sleep_df_filtered = sleep_df[sleep_df['sleep_wear'] != False].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a86aaf-3c14-4ff9-9592-849dd3e5f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sleep_df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5a8adb-eddb-4da9-83ed-d0e237d7d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c70029-268b-4341-9ae0-a03809e1be5f",
   "metadata": {},
   "source": [
    "## calculate week and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa8d4b2-614e-4e4a-af08-ac1f5aeab77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'inbed_time_utc' is in datetime format\n",
    "sleep_df_filtered['inbed_time_utc'] = pd.to_datetime(sleep_df_filtered['inbed_time_utc'], errors='coerce')\n",
    "\n",
    "# Extract only the date part (ignore the time) and calculate the week number\n",
    "sleep_df_filtered['inbed_date_utc'] = sleep_df_filtered['inbed_time_utc'].dt.date  # Keep only the date part\n",
    "\n",
    "# Now calculate the week number based on the date\n",
    "sleep_df_filtered['week_number'] = pd.to_datetime(sleep_df_filtered['inbed_date_utc']).dt.isocalendar().week\n",
    "\n",
    "# Check the result\n",
    "print(sleep_df_filtered[['inbed_date_utc', 'week_number']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c290941-de04-42bd-9e23-9bdb05049f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'week_number_cst' column\n",
    "sleep_df_filtered = sleep_df_filtered.drop(columns=['inbed_date_utc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc26487-bea8-4a7f-be0d-b7154ddf2f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named 'df'\n",
    "sleep_df_filtered.to_csv('sleep_variables.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22c4f05-e809-4d76-8f4c-20291e016d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df_filtered.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a66542-ecd3-49ba-9594-f6e01918c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7155dd2c-5e9a-4f5c-92cc-a48189b95cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df_filtered['week_number'].nunique()     ### 52.14 weeks in a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e7f41-fbf3-4497-8203-e301f8f0a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'subj' and 'week_number' and count the occurrences (size of each group)\n",
    "week_counts = sleep_df_filtered.groupby(['subj', 'week_number']).size().reset_index(name='count')\n",
    "\n",
    "# Find the maximum count from the grouped data\n",
    "max_count = week_counts['count'].max()\n",
    "\n",
    "# Print the maximum count\n",
    "print(f\"The maximum count of entries for a unique week number and subject combination is {max_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ce0521-36fd-46dd-9e4c-f43634e86fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'week_number_cst' column\n",
    "#sleep_df_filtered = sleep_df_filtered.drop(columns=['week_number_cst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a10ff5-560e-4e22-b911-332acfb66f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of NaN values in the 'inbed_time_utc' column\n",
    "nan_count = sleep_df_filtered['inbed_time_utc'].isna().sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"The number of NaN values in 'inbed_time_utc' column is: {nan_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d30bbfd-c261-4a5c-9d0c-d9795d6fa51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'inbed_time_utc' is NaN\n",
    "sleep_df_filtered = sleep_df_filtered.dropna(subset=['inbed_time_utc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e4015f-4add-4a6c-a295-c3014d78cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'inbed_time_utc' is in datetime format if it isn't already\n",
    "sleep_df_filtered['inbed_time_utc'] = pd.to_datetime(sleep_df_filtered['inbed_time_utc'], errors='coerce')\n",
    "\n",
    "# Fill NaN values with a default year (e.g., 0 or any year you prefer)\n",
    "sleep_df_filtered['year'] = sleep_df_filtered['inbed_time_utc'].dt.year.fillna(0).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef463ee-69cf-4cc0-9a04-9903c0e00b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'subj' and 'week_number', and get the number of unique 'year' values for each group\n",
    "year_counts = sleep_df_filtered.groupby(['subj', 'week_number'])['year'].nunique().reset_index(name='unique_year_count')\n",
    "\n",
    "# Filter for rows where the count of unique 'year' is greater than 1\n",
    "multiple_years = year_counts[year_counts['unique_year_count'] > 1]\n",
    "\n",
    "# Get the list of subj names for these pairs\n",
    "subj_names = multiple_years[['subj', 'week_number']]\n",
    "\n",
    "# Print the result\n",
    "print(\"The subj and week_number pairs where more than one unique year exists:\")\n",
    "print(subj_names)\n",
    "\n",
    "# Get the count of such pairs\n",
    "count_multiple_years = subj_names.shape[0]\n",
    "\n",
    "# Print the count\n",
    "print(f\"The count of pairs where subj and week_number have more than one unique year is: {count_multiple_years}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e26092b-5e00-4068-9bea-16993bb54fa2",
   "metadata": {},
   "source": [
    "## calculate the metrics of sleep based on each subj, week and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd42cad-c90f-49e2-ac80-651cf7cfb8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'subj', 'week_number', and 'year' and calculate the mean for the required columns\n",
    "mean_values = sleep_df_filtered.groupby(['subj', 'week_number', 'year']).agg(\n",
    "    mean_efficiency=('efficiency', 'mean'),\n",
    "    sd_efficiency=('efficiency', 'std'),\n",
    "    mean_tst=('asleep_tst_min', 'mean'),\n",
    "    sd_tst=('asleep_tst_min', 'std'),\n",
    ").reset_index()\n",
    "\n",
    "# Add 'inbed_time_utc' and 'inbed_time_cst' to the new DataFrame\n",
    "# For 'inbed_time_utc', we will use the first entry of each group (or any other aggregation as needed)\n",
    "mean_values['inbed_time_utc'] = sleep_df_filtered.groupby(['subj', 'week_number', 'year'])['inbed_time_utc'].first().reset_index(drop=True)\n",
    "mean_values['inbed_time_cst'] = sleep_df_filtered.groupby(['subj', 'week_number', 'year'])['inbed_time_cst'].first().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a06a4b-781d-4060-9894-8fc53f492935",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1557fcba-4c00-4e84-b8f3-3d285672eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named 'df'\n",
    "mean_values.to_csv('mean_sleep_variables_v1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab38df4-9375-428d-a004-2c4961f1b447",
   "metadata": {},
   "source": [
    "## load FINAL_MODEL dataset AND ADD SLEEP VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c91794-d8dd-416d-9bf4-2e5695f818c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = r'C:/Users/aparn/Box/InTrans/RWRAD_Internal/Final_files_with_variables/Final_list_of_variables/weekly_stats_demo_cleaned_for_model.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "final_df_model = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3de3925-ace8-4a24-9cae-c7ca98a19517",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582afc6b-6774-49d0-9d0c-192b625f7d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 'mean_values' DataFrame with 'final_df_model' based on 'subj', 'week_number', and 'year'\n",
    "merged_df = final_df_model.merge(mean_values[['subj', 'week_number', 'year', 'mean_efficiency', 'sd_efficiency', 'mean_tst', 'sd_tst']],\n",
    "                                 on=['subj', 'week_number', 'year'],\n",
    "                                 how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b83f4f3-197a-4358-9983-a1b2f959d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c46ab41-fdbb-4a6a-aa80-a0702a992f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for rows where 'mean_efficiency' is NaN after the merge\n",
    "missing_rows = merged_df[merged_df['mean_efficiency'].isna()]\n",
    "\n",
    "print(f\"Rows in 'final_df_model' that have no match in 'mean_values':\")\n",
    "print(missing_rows[['subj', 'week_number', 'year']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc37c2b4-15a3-4577-9ef5-e72afa5ddaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named 'df'\n",
    "merged_df.to_csv('weekly_stats_demo_cleaned_for_model_v3.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ef1108-f886-4180-bb1d-17679fe1aed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02059ec4-1544-41c0-bdd8-2715e8edae98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d36e0df-7bc5-4397-801f-43ccf8509283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
