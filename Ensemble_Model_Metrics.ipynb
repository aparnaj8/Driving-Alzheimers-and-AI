{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c4c427-a739-4613-8567-fcf737971005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a9e85-ca04-43bf-91a6-83a181fc53d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path =  r'C:/Users/aparn/Box/InTrans/RWRAD_Internal/Final_files_with_variables/LOSO_CV results/losocv_results_with_hyperparameter_tuning_parallel_demo_sleep.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "all_var_df= pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1c803c-4d82-4b2a-aa6f-ab22188751f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_var_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0219e785-165b-44f1-954d-23dfc912eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_var_df['Subject'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e97d42-38e2-4097-a9c0-6b8e02de9cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the DataFrame is named `df` and the relevant columns are 'subj' for the subject and 'True_Label' for the label\n",
    "\n",
    "# Group by 'subj' (subject) and check unique values in 'True_Label' for each subject\n",
    "unique_label_counts = all_var_df.groupby('Subject')['True Label'].nunique()\n",
    "\n",
    "# Count how many subjects have more than one unique value for 'True_Label'\n",
    "subjects_with_multiple_labels = (unique_label_counts > 1).sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of subjects with more than 1 unique value for True Label: {subjects_with_multiple_labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70617506-b70b-422e-a293-ef492b4a222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the DataFrame is named `df` and the relevant columns are 'subj' for the subject and 'True_Label' for the label\n",
    "\n",
    "# Group by 'subj' and check how many unique values exist for 'True_Label'\n",
    "unique_label_counts = all_var_df.groupby('Subject')['True Label'].nunique()\n",
    "\n",
    "# Get the subjects where the number of unique labels is greater than 1\n",
    "subjects_with_multiple_labels = unique_label_counts[unique_label_counts > 1].index\n",
    "\n",
    "# Print the subjects with more than 1 unique value for True Label\n",
    "print(\"Subjects with more than 1 unique value for True Label:\")\n",
    "print(subjects_with_multiple_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f318d2d-8499-429b-ae4d-56cbb38be777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the DataFrame is named `df` with columns 'subj', 'True_Label', and 'Predicted_Label'\n",
    "\n",
    "# Group by 'subj' to summarize data for each subject\n",
    "summary_df = all_var_df.groupby('Subject').agg(\n",
    "    num_data_points=('Subject', 'size'),\n",
    "    true_label=('True Label', lambda x: x.iloc[0] if len(x.unique()) == 1 else 'Multiple'),  # Repeat or mark 'Multiple' if more than 1 unique True_Label\n",
    "    num_predicted_1=('Predicted Label', lambda x: (x == 1).sum()),  # Count of Predicted_Label == 1\n",
    "    num_predicted_0=('Predicted Label', lambda x: (x == 0).sum())  # Count of Predicted_Label == 0\n",
    ")\n",
    "\n",
    "# Add a column for Final_call: 1 if num_predicted_1 > num_predicted_0, otherwise 0\n",
    "summary_df['Final_call'] = (summary_df['num_predicted_1'] > summary_df['num_predicted_0']).astype(int)\n",
    "\n",
    "# Reset index to make 'subj' a regular column again (for easier viewing)\n",
    "summary_df.reset_index(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9205d527-0c43-4e6e-9f3a-cdead3e64e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.head(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9ce060-831b-40af-8763-95ff6f2a012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0701b51b-fcc0-45d3-8897-9226a3236ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming `expanded_summary_df` is your DataFrame\n",
    "# Remove rows where the 'true_label' is \"Multiple\"\n",
    "filtered_df = summary_df[summary_df['true_label'] != 'Multiple']\n",
    "\n",
    "# Create a new column to check if True_Label matches Final_Call\n",
    "filtered_df['correct_prediction'] = filtered_df['true_label'] == filtered_df['Final_call']\n",
    "\n",
    "# Calculate accuracy by dividing the number of correct predictions by the total number of data points\n",
    "accuracy = filtered_df['correct_prediction'].sum() / len(filtered_df)\n",
    "\n",
    "# Calculate the count of correct predictions\n",
    "correct_prediction_count = filtered_df['correct_prediction'].sum()\n",
    "\n",
    "# Print the accuracy and the count of correct predictions\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Count of Correct Predictions: {correct_prediction_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac93306-d3fe-400c-9b3f-65314afe00b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e93bc35-e97e-4c18-8649-04c174778fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create variables for True Positives, False Positives, False Negatives, and True Negatives\n",
    "tp = ((filtered_df['true_label'] == 1) & (filtered_df['Final_call'] == 1)).sum()\n",
    "fp = ((filtered_df['true_label'] == 0) & (filtered_df['Final_call'] == 1)).sum()\n",
    "fn = ((filtered_df['true_label'] == 1) & (filtered_df['Final_call'] == 0)).sum()\n",
    "tn = ((filtered_df['true_label'] == 0) & (filtered_df['Final_call'] == 0)).sum()\n",
    "\n",
    "# Calculate Precision, Recall, and F1 Score\n",
    "precision = tp / (tp + fp) if (tp + fp) != 0 else 0  # Avoid division by zero\n",
    "recall = tp / (tp + fn) if (tp + fn) != 0 else 0  # Avoid division by zero\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0  # Avoid division by zero\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed924ab4-71f0-45e6-91f6-88d957a1d644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca4480-3257-4762-b361-ca47611d759d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57908a2-0bbc-4dd7-82bd-f629503b0e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
