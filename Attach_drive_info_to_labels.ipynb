{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1235b198-afbd-439e-99f9-1b6a040c6c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba5b8f8-626a-4c0e-bddf-88bfe07735c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9701fdc9-6d36-488c-bbc5-2ee9bbec2a77",
   "metadata": {},
   "source": [
    "## Attach the end location home information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa744de8-8ee9-4839-bdb7-091e663647c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = '/Users/aparnaj8/Box/InTrans/RWRAD_Internal/Souradeep_Trip_Info/RWRAD_all_label.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "labels_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69916cd9-5996-4e8e-abcd-f96427735683",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a0332-e80b-405f-8f4b-fe9e193dfb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column 'B'\n",
    "labels_df = labels_df.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e49d9f-97a9-405b-a0ff-307b89d2745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the folder containing GPS files\n",
    "folder_path = r\"C:\\Users\\aparnaj8\\Box\\Data (Matthew Rizzo)\\DataAnalysis\\ReferenceDatabases\\BlackBox_GPSDrivingLocations\\BlackBox_GPSDrivingLocations_1hz\"\n",
    "\n",
    "# Initialize a list to store the final results and processed files\n",
    "results = []\n",
    "processed_files = []  # List to track processed files\n",
    "\n",
    "# Iterate over each unique subject in labels_df\n",
    "for subj in labels_df['subj'].unique():\n",
    "    # Construct the file path for the subject's GPS file\n",
    "    file_name = f\"{subj}_BlackBox_GPSDrivingLocations_1hz.csv\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Started processing file: {file_name}\")  # Announce processing start\n",
    "\n",
    "        # Load the GPS file into a DataFrame\n",
    "        gps_df = pd.read_csv(file_path)\n",
    "\n",
    "        # Ensure time columns are in datetime format for proper comparison\n",
    "        labels_df['time_utc'] = pd.to_datetime(labels_df['time_utc'])\n",
    "        gps_df['time_utc'] = pd.to_datetime(gps_df['time_utc'])\n",
    "\n",
    "        # Filter gps_df for rows where time_cat = 'end'\n",
    "        gps_df_filtered = gps_df[gps_df['time_cat'] == 'end']\n",
    "\n",
    "        # Filter the labels_df for the current subject\n",
    "        subj_labels = labels_df[labels_df['subj'] == subj]\n",
    "\n",
    "        # Perform a left merge to retain all rows from labels_df\n",
    "        merged_df = pd.merge(\n",
    "            subj_labels,\n",
    "            gps_df_filtered[['time_utc', 'drive', 'gps_lat', 'gps_long']],  # Columns to match and attach\n",
    "            on='time_utc',\n",
    "            how='left'  # Use 'left' to keep all rows from labels_df\n",
    "        )\n",
    "\n",
    "        # Append the merged data to the results list\n",
    "        results.append(merged_df)\n",
    "\n",
    "        # Mark the file as processed\n",
    "        processed_files.append(file_name)\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "if results:\n",
    "    final_df = pd.concat(results, ignore_index=True)\n",
    "else:\n",
    "    final_df = pd.DataFrame()  # Handle case where no data is processed\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(final_df)\n",
    "\n",
    "# Display the list of processed files\n",
    "print(\"\\nFiles Processed:\")\n",
    "for file in processed_files:\n",
    "    print(f\" - {file}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723ae376-e17f-4658-831c-92dd81e2f579",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce52880-c2d9-4e4e-a306-76a5a533bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d77be3-7dbb-4f0d-910b-c3aec2b60062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of NaN values in each column\n",
    "nan_counts_per_column = final_df.isna().sum()\n",
    "\n",
    "# Print the count of NaN values for each column\n",
    "print(\"Count of NaN values per column:\")\n",
    "print(nan_counts_per_column)\n",
    "\n",
    "# Count the total number of rows with any NaN values\n",
    "rows_with_nan = final_df.isna().any(axis=1).sum()\n",
    "print(f\"\\nTotal number of rows with NaN values: {rows_with_nan}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be487702-063e-422f-a360-aa653e192b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final DataFrame to a CSV file (if needed)\n",
    "output_path = r\"/Users/aparnaj8/Box/InTrans/RWRAD_Internal/Trip_variable/RWRAD_end_trip_info.csv\"\n",
    "final_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55227862-2d0c-4ce7-963e-ea43275b0d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd054c5b-c695-4756-8745-5ad671b855f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['subj'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276fa89d-2faf-4418-90f0-bc94b719f1ec",
   "metadata": {},
   "source": [
    "##  Extract only home location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9137a7e-1a8f-484a-82ba-e0950f04f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = r\"/Users/aparnaj8/Box/InTrans/RWRAD_Internal/Trip_variable/RWRAD_end_trip_info.csv\"\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "final_df= pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c934c-ac50-4f2e-bff5-d4febcfe1065",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f850cf-5c94-4209-9472-cac158ab2d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for rows where the 'labels' column is 'home'\n",
    "home_df = final_df[final_df['labels'] == 'home']\n",
    "home_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c56b8-8bed-4b9c-ac95-b6b30e3f8d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(home_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ed1fc8-11d3-4057-b672-c48aae2854ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df['subj'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ddd13c-21c9-4629-98f6-e4574109b467",
   "metadata": {},
   "source": [
    "## Extract first value of lat and long for every subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab53d6f9-43be-409a-9c20-17582ce44f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'subj' and keep the first entry for each subject based on gps_lat and gps_long\n",
    "home_df_first_entry = home_df.groupby('subj').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff69d1a-da9b-4af9-98f3-6b495ff69cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df_first_entry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3831f83-b0cf-45e1-a07b-e141fd760044",
   "metadata": {},
   "source": [
    "## Calculate the distance for all Csvs ( some csv files are misisng due to lack of home info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197eaad6-e569-42b5-8935-cf0e34697878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Initialize the final output dataframe\n",
    "final_output_df = pd.DataFrame(columns=['subj', 'drive', 'distance', 'label'])\n",
    "\n",
    "# Path to the GPS data files\n",
    "gps_files_path = r\"C:\\Users\\aparnaj8\\Box\\Data (Matthew Rizzo)\\DataAnalysis\\ReferenceDatabases\\BlackBox_GPSDrivingLocations\\BlackBox_GPSDrivingLocations_1hz\"\n",
    "\n",
    "# Get all CSV files from the folder\n",
    "gps_files = [file for file in os.listdir(gps_files_path) if file.endswith(\".csv\")]\n",
    "\n",
    "# Iterate through all CSV files\n",
    "for file in gps_files:\n",
    "    # Load the current GPS file\n",
    "    gps_df = pd.read_csv(os.path.join(gps_files_path, file))\n",
    "    gps_df = gps_df[gps_df['time_cat'] == 'start']  # Filter for 'start' only\n",
    "\n",
    "    # Print which file is being processed\n",
    "    print(f\"Processing file: {file}\")\n",
    "\n",
    "    # Iterate over each row in home_df_first_entry to match with GPS data\n",
    "    for index, row in home_df_first_entry.iterrows():\n",
    "        # Match the subject in the GPS data\n",
    "        matching_gps = gps_df[gps_df['subj'] == row['subj']]\n",
    "\n",
    "        if not matching_gps.empty:\n",
    "            # Calculate the geodesic distance for each match if coordinates are valid\n",
    "            home_lat = row['gps_lat']\n",
    "            home_lon = row['gps_long']\n",
    "\n",
    "            # Skip if the home coordinates are missing or invalid\n",
    "            if pd.isna(home_lat) or pd.isna(home_lon):\n",
    "                continue\n",
    "\n",
    "            home_point = (home_lat, home_lon)\n",
    "            \n",
    "            # For each matching entry, calculate the distance and label\n",
    "            for _, gps_row in matching_gps.iterrows():\n",
    "                gps_lat = gps_row['gps_lat']\n",
    "                gps_lon = gps_row['gps_long']\n",
    "                \n",
    "                # Skip if GPS coordinates are missing or invalid\n",
    "                if pd.isna(gps_lat) or pd.isna(gps_lon):\n",
    "                    continue\n",
    "\n",
    "                gps_point = (gps_lat, gps_lon)\n",
    "\n",
    "                # Calculate distance in feet\n",
    "                distance = geodesic(home_point, gps_point).feet\n",
    "                \n",
    "                # Assign label based on distance\n",
    "                label = 'home' if distance < 100 else 'not_home'\n",
    "                \n",
    "                # Prepare the new row as a DataFrame\n",
    "                new_row = pd.DataFrame({\n",
    "                    'subj': [row['subj']],\n",
    "                    'drive': [gps_row['drive']],\n",
    "                    'distance': [distance],\n",
    "                    'label': [label]\n",
    "                })\n",
    "                \n",
    "                # Concatenate the new row to the final dataframe\n",
    "                final_output_df = pd.concat([final_output_df, new_row], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938eddee-8726-43fe-8573-56b145762256",
   "metadata": {},
   "source": [
    "## Check duplicate count of subj and drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fd913d-fa3a-4065-a40e-01de3a1e5522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates based on 'subj' and 'drive'\n",
    "duplicates = final_output_df[final_output_df.duplicated(subset=['subj', 'drive'], keep=False)]\n",
    "\n",
    "# Count the number of duplicates\n",
    "duplicate_count = duplicates.shape[0]  # or len(duplicates)\n",
    "print(f\"Number of duplicate combinations of 'subj' and 'drive': {duplicate_count}\")\n",
    "\n",
    "# Optionally, you can display the duplicate rows for inspection\n",
    "print(duplicates[['subj', 'drive']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165600ea-05ce-4823-8636-f37287550fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of unique 'subj' values\n",
    "unique_subj_count = final_output_df['subj'].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of unique subjects: {unique_subj_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b8c93-8cd4-4656-acb2-a92d9b241f95",
   "metadata": {},
   "source": [
    "## Save the dataframe as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dff072-d775-40ca-8703-63500ab7e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save the final dataframe to a CSV\n",
    "final_output_df.to_csv(\"RWRAD_start_trip_home_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f984af6-8ad1-417d-bd83-fd5dea194731",
   "metadata": {},
   "source": [
    "## Check the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d86adc-b945-468e-a295-e971570adf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025e60af-fc5e-4fe6-b509-be9b8eba3a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984fcabe-8929-4c00-b3fa-51c4e076db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_count = final_output_df[final_output_df['label'] == 'home'].shape[0]\n",
    "print(home_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa7e788-c8e7-4e73-8282-4162b1b582d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the rows where the label is 'home'\n",
    "home_label_df = final_output_df[final_output_df['label'] == 'home']\n",
    "\n",
    "# Find the row with the maximum distance\n",
    "max_distance_row = home_label_df.loc[home_label_df['distance'].idxmax()]\n",
    "\n",
    "# Display the row with the maximum distance\n",
    "print(max_distance_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50040d39-55b3-4c09-a6a1-b9c8377e9e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where distance is between 50 and 100 feet inclusive\n",
    "filtered_df = final_output_df[(final_output_df['distance'] >= 50) & (final_output_df['distance'] <= 100)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c56d28-ac30-44a3-bd27-66fe8b18e57a",
   "metadata": {},
   "source": [
    "## Test code for one csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adf7423-e51c-436b-9e38-1e53e99cd19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "\n",
    "# Initialize the final output dataframe\n",
    "final_output_df = pd.DataFrame(columns=['subj', 'drive', 'distance', 'label'])\n",
    "\n",
    "# Path to the GPS data files\n",
    "gps_files_path = r\"C:\\Users\\aparnaj8\\Box\\Data (Matthew Rizzo)\\DataAnalysis\\ReferenceDatabases\\BlackBox_GPSDrivingLocations\\BlackBox_GPSDrivingLocations_1hz\"\n",
    "\n",
    "# Get the first CSV file from the folder\n",
    "gps_files = [file for file in os.listdir(gps_files_path) if file.endswith(\".csv\")]\n",
    "first_file = gps_files[0]  # The first CSV file\n",
    "\n",
    "# Process the first file only\n",
    "gps_df = pd.read_csv(os.path.join(gps_files_path, first_file))\n",
    "gps_df = gps_df[gps_df['time_cat'] == 'start']  # Filter for 'start' only\n",
    "\n",
    "# Print which file is being processed\n",
    "print(f\"Processing file: {first_file}\")\n",
    "\n",
    "# Iterate over each row in home_df_first_entry to match with GPS data\n",
    "for index, row in home_df_first_entry.iterrows():\n",
    "    # Match the subject in the GPS data\n",
    "    matching_gps = gps_df[gps_df['subj'] == row['subj']]\n",
    "\n",
    "    if not matching_gps.empty:\n",
    "        # Calculate the geodesic distance for each match\n",
    "        home_point = (row['gps_lat'], row['gps_long'])\n",
    "        \n",
    "        # For each matching entry, calculate the distance and label\n",
    "        for _, gps_row in matching_gps.iterrows():\n",
    "            gps_point = (gps_row['gps_lat'], gps_row['gps_long'])\n",
    "            \n",
    "            # Calculate distance in feet\n",
    "            distance = geodesic(home_point, gps_point).feet\n",
    "            \n",
    "            # Assign label based on distance\n",
    "            label = 'home' if distance < 50 else 'not_home'\n",
    "            \n",
    "            # Prepare the new row as a DataFrame\n",
    "            new_row = pd.DataFrame({\n",
    "                'subj': [row['subj']],\n",
    "                'drive': [gps_row['drive']],\n",
    "                'distance': [distance],\n",
    "                'label': [label]\n",
    "            })\n",
    "            \n",
    "            # Concatenate the new row to the final dataframe\n",
    "            final_output_df = pd.concat([final_output_df, new_row], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eaa3c0-c6d4-477c-a4fa-c6f512cf63ed",
   "metadata": {},
   "source": [
    "## find the home information for the remaining subjects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38f1a13-8847-472f-96ff-1a5b21e0b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:\\\\Users\\\\aparnaj8\\\\Box\\\\Data (Matthew Rizzo)\\\\DataAnalysis\\\\FormattingQAChecks\\\\REDCap_Formatting\\\\REDCap_Format_Data\\\\dlq.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "dlq_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8818fce4-9bcb-4b4d-8d5d-297c3cd330d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f1773-2795-4d60-98d2-011fd39e1f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to get rows where 'type' is 'home'\n",
    "home_df = dlq_df[dlq_df['type'] == 'home']\n",
    "\n",
    "# Get unique combinations of 'subj' and 'type'\n",
    "unique_home_combinations = home_df[['subj', 'type']].drop_duplicates()\n",
    "\n",
    "# Merge the unique combinations with the original DataFrame to get 'gps_lat' and 'gps_long'\n",
    "home_gps_info = pd.merge(unique_home_combinations, dlq_df[['subj', 'type', 'gps_lat', 'gps_long']], on=['subj', 'type'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc3857e-d50f-4532-ac1b-5f4ab31d891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_gps_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fac57a-2817-4928-a531-3705f618f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the 'home_gps_info' DataFrame to keep only those rows where 'subj' is not in 'final_output_df'\n",
    "filtered_home_gps_info = home_gps_info[~home_gps_info['subj'].isin(home_df_first_entry['subj'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb00901d-0fb5-423d-b8d7-4edc09c76d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_home_gps_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9e7430-bc80-48fe-b391-20c6f0982516",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_home_gps_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04d79ca-c315-48b3-962b-6d7334b7e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered DataFrame to CSV\n",
    "filtered_home_gps_info.to_csv('home_information_for_remaining_subjects.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a012e-ee7f-4b5c-9708-7c201d136723",
   "metadata": {},
   "source": [
    "## Do the same process for the remaining csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2df6ef-dd3d-4c4c-9b96-97453768b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Initialize the final output dataframe\n",
    "final_home_gps_info = pd.DataFrame(columns=['subj', 'drive', 'distance', 'label'])\n",
    "\n",
    "# Path to the GPS data files\n",
    "gps_files_path = r\"C:\\Users\\aparnaj8\\Box\\Data (Matthew Rizzo)\\DataAnalysis\\ReferenceDatabases\\BlackBox_GPSDrivingLocations\\BlackBox_GPSDrivingLocations_1hz\"\n",
    "\n",
    "# Get all CSV files from the folder\n",
    "gps_files = [file for file in os.listdir(gps_files_path) if file.endswith(\".csv\")]\n",
    "\n",
    "# Iterate through all CSV files\n",
    "for file in gps_files:\n",
    "    # Load the current GPS file\n",
    "    gps_df = pd.read_csv(os.path.join(gps_files_path, file))\n",
    "    gps_df = gps_df[gps_df['time_cat'] == 'start']  # Filter for 'start' only\n",
    "\n",
    "    # Print which file is being processed\n",
    "    print(f\"Processing file: {file}\")\n",
    "\n",
    "    # Iterate over each row in filtered_home_gps_info to match with GPS data\n",
    "    for index, row in filtered_home_gps_info.iterrows():\n",
    "        # Match the subject in the GPS data\n",
    "        matching_gps = gps_df[gps_df['subj'] == row['subj']]\n",
    "\n",
    "        if not matching_gps.empty:\n",
    "            # Calculate the geodesic distance for each match if coordinates are valid\n",
    "            home_lat = row['gps_lat']\n",
    "            home_lon = row['gps_long']\n",
    "\n",
    "            # Skip if the home coordinates are missing or invalid\n",
    "            if pd.isna(home_lat) or pd.isna(home_lon):\n",
    "                continue\n",
    "\n",
    "            home_point = (home_lat, home_lon)\n",
    "            \n",
    "            # For each matching entry, calculate the distance and label\n",
    "            for _, gps_row in matching_gps.iterrows():\n",
    "                gps_lat = gps_row['gps_lat']\n",
    "                gps_lon = gps_row['gps_long']\n",
    "                \n",
    "                # Skip if GPS coordinates are missing or invalid\n",
    "                if pd.isna(gps_lat) or pd.isna(gps_lon):\n",
    "                    continue\n",
    "\n",
    "                gps_point = (gps_lat, gps_lon)\n",
    "\n",
    "                # Calculate distance in feet\n",
    "                distance = geodesic(home_point, gps_point).feet\n",
    "                \n",
    "                # Assign label based on distance\n",
    "                label = 'home' if distance < 100 else 'not_home'\n",
    "                \n",
    "                # Prepare the new row as a DataFrame\n",
    "                new_row = pd.DataFrame({\n",
    "                    'subj': [row['subj']],\n",
    "                    'drive': [gps_row['drive']],\n",
    "                    'distance': [distance],\n",
    "                    'label': [label]\n",
    "                })\n",
    "                \n",
    "                # Concatenate the new row to the final dataframe\n",
    "                final_home_gps_info = pd.concat([final_home_gps_info, new_row], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b18e1d-30aa-48ba-aa21-9f6899705281",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_home_gps_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded219b5-c85f-4cb0-ae22-e2a17b2fd021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered DataFrame to CSV\n",
    "final_home_gps_info.to_csv('RWRAD_start_trip_home_info_for_remaining_subjects.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a6319f-287e-4292-bb13-227b9083a2ed",
   "metadata": {},
   "source": [
    "## Read the merged file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff960b7-ff4a-4cf1-9519-b9b7f1d75daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = '/Users/aparnaj8/Box/InTrans/RWRAD_Internal/Trip_variable/RWRAD_start_trip_info_allsubjects.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "all_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc7eda-74cb-4d66-899e-bc75c2e219c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c669f5c-ac97-4a83-b150-ffe3a708bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique 'subj' values from all_df\n",
    "unique_subj = all_df['subj'].unique()\n",
    "\n",
    "\n",
    "# Optional: You can also get the count of unique subjects\n",
    "unique_subj_count = len(unique_subj)\n",
    "print(f\"Number of unique subjects: {unique_subj_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84847f5e-34e7-418a-ab25-1d0acfdf238d",
   "metadata": {},
   "source": [
    "## Filter only those trips which started from home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a0b3ba-bd38-48b6-b8e0-1a7979e9136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where label is 'home'\n",
    "home_df = all_df[all_df['label'] == 'home']\n",
    "\n",
    "# Optional: Get the count of rows where label is 'home'\n",
    "home_count = home_df.shape[0]\n",
    "print(f\"Number of rows with label 'home': {home_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e164515-cabb-4149-b2fe-066286fed93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique 'subj' values from all_df\n",
    "unique_subj = home_df['subj'].unique()\n",
    "\n",
    "# Optional: You can also get the count of unique subjects\n",
    "unique_subj_count = len(unique_subj)\n",
    "print(f\"Number of unique subjects: {unique_subj_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c92eb0-200d-4755-992f-104172bfaefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3faae4f-36cd-49f0-a2ce-18cd1daecf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered DataFrame to CSV\n",
    "home_df.to_csv('RWRAD_start_trip_home_only_for_all_subjects.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca58ed5-ab2f-4b05-b195-d7d4754855eb",
   "metadata": {},
   "source": [
    "## Find trips which are <15 or 25 miles from home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ba5a70-18d5-4ee8-a05c-83d87250edd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = '/Users/aparnaj8/Box/Data (Matthew Rizzo)\\DataAnalysis\\FormattingQAChecks\\BlackBox_FormattingQAChecks\\BlackBox_FormatQA_Data\\DataSummaries_1hz/BlackBox_1hz_byDriveSummary.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "drive_summary_df= pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d2c91e-0052-4f87-952b-ed35d2648e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_summary_df['time_cat'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660b38b8-4fe3-43fc-a4ba-9707a6d8b4eb",
   "metadata": {},
   "source": [
    "### Save only required variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1757c6-3bfd-49f2-be15-c324713b7f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the specified columns\n",
    "filtered_drive_summary_df = drive_summary_df[['subj', 'drive', 'time_start_utc', 'time_end_utc', 'time_start_cst', 'time_end_cst', 'time_weekday', 'duration_minutes', 'distance_miles', 'speed_mph_mean']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b35460-9d4b-439c-a47c-535cb59a6767",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_drive_summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0106773d-1ba0-4a36-8f91-7005b7f80c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames on 'subj' and 'drive'\n",
    "merged_df = pd.merge(filtered_drive_summary_df, home_df[['subj', 'drive', 'distance', 'label']], on=['subj', 'drive'], how='left')\n",
    "\n",
    "# Rename the 'distance' column to 'calc_distance'\n",
    "merged_df.rename(columns={'distance': 'home_distance'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abfeee1-2628-4a08-93d1-842ad3edd575",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6bc340-3f04-41d7-b69e-deeb2c389eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2431eef7-b06a-4658-bd96-d35ac09fa98a",
   "metadata": {},
   "source": [
    "# Add 15 miles and 25 miles column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad949eb-3ccf-4564-bdc8-48f3f444575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a new column '15_miles_from_home' where the distance is less than 15 miles and label is 'home'\n",
    "merged_df['15_miles_from_home'] = merged_df.apply(\n",
    "    lambda row: 'yes' if row['label'] == 'home' and row['distance_miles'] < 15 else ('no' if row['label'] == 'home' else np.nan), axis=1)\n",
    "\n",
    "# Create a new column '25_miles_from_home' where the distance is less than 25 miles and label is 'home'\n",
    "merged_df['25_miles_from_home'] = merged_df.apply(\n",
    "    lambda row: 'yes' if row['label'] == 'home' and row['distance_miles'] < 25 else ('no' if row['label'] == 'home' else np.nan), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d9cbb1-ca11-40df-a73b-a39f28ea611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to convert to datetime\n",
    "columns_to_convert = ['time_start_utc', 'time_end_utc', 'time_start_cst', 'time_end_cst']  # Replace with actual column names\n",
    "\n",
    "# Convert specified columns to datetime format\n",
    "for column in columns_to_convert:\n",
    "    merged_df[column] = pd.to_datetime(merged_df[column], errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790adf72-49a0-436e-bdbd-5c9cfec1be77",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211aeeb2-3bf3-4126-8c0b-46f2e0f8cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered DataFrame to CSV\n",
    "merged_df.to_csv('RWRAD_15_25_miles_from_home.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0c1bc1-6e18-448a-826d-2760f476ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of 'yes', 'no', and NaN for the '15_miles_from_home' column\n",
    "count_15_miles = merged_df['15_miles_from_home'].value_counts(dropna=False)\n",
    "\n",
    "# Count occurrences of 'yes', 'no', and NaN for the '25_miles_from_home' column\n",
    "count_25_miles = merged_df['25_miles_from_home'].value_counts(dropna=False)\n",
    "\n",
    "# Display the counts\n",
    "print(\"Count for '15_miles_from_home':\")\n",
    "print(count_15_miles)\n",
    "\n",
    "print(\"\\nCount for '25_miles_from_home':\")\n",
    "print(count_25_miles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350a72cd-e2e8-4c2c-a05c-9ccecda4b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec76f5f5-4c40-4839-b12d-cad7fd014115",
   "metadata": {},
   "source": [
    "## Attach Trip Chaining Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adece4f-a6d0-4e9b-a774-6c3f1f822696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = '/Users/aparnaj8/Box/InTrans/RWRAD_Internal/Final_files_with_variables/Trip_information/RWRAD_15_25_miles_from_home_week_info.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "trip_summary_df= pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059b9ca0-dea5-4b9d-8dc7-f67e04ce3c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e63a2d-fa55-49d4-bac2-225ec4c69935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = '/Users/aparnaj8/Box/InTrans/RWRAD_Internal/Trip_variable/soura_start_end_rwrad.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "start_df= pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9f79ea-1235-430f-9afa-4417e6f23028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe based on the conditions\n",
    "start_df_filtered = start_df[(start_df['time_cat'] == 'start')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641373e7-7bf4-48ec-91e0-6beed0c21053",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee734d23-f2bd-4566-9642-135dd56f70d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = '/Users/aparnaj8/Box/InTrans/RWRAD_Internal/Souradeep_Trip_Info/RWRAD_all_label_wdrive.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "end_df= pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29533a9e-c4d7-4ce7-a392-e9d732ad1ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique 'subj' values from all_df\n",
    "unique_subj = end_df['labels'].unique()\n",
    "unique_subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c5107a-d200-4f74-a5a6-b275d455d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268921b5-deff-495b-9bda-a82ad7625388",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_summary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c14db2a-3220-4a91-9f6c-502975335321",
   "metadata": {},
   "source": [
    "#### Attach start and end home information to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6961f5d3-cfaa-4557-8b1a-c812c61c08fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add start_location and end_location columns with default value\n",
    "trip_summary_df[\"start_location\"] = None\n",
    "trip_summary_df[\"end_location\"] = None\n",
    "\n",
    "# Create a mapping dictionary for end_df (subj, drive) -> label\n",
    "start_location_mapping = start_df_filtered.set_index([\"subj\", \"drive\"])[\"labels\"].to_dict()\n",
    "\n",
    "# Update the end_location column using the mapping\n",
    "trip_summary_df[\"start_location\"] = trip_summary_df.set_index([\"subj\", \"drive\"]).index.map(start_location_mapping)\n",
    "\n",
    "# Create a mapping dictionary for end_df (subj, drive) -> label\n",
    "end_location_mapping = end_df.set_index([\"subj\", \"drive\"])[\"labels\"].to_dict()\n",
    "\n",
    "# Update the end_location column using the mapping\n",
    "trip_summary_df[\"end_location\"] = trip_summary_df.set_index([\"subj\", \"drive\"]).index.map(end_location_mapping)\n",
    "\n",
    "# Convert None to a default value, e.g., \"unknown\" (if needed)\n",
    "trip_summary_df[\"end_location\"].fillna(\"None\", inplace=True)\n",
    "\n",
    "# Convert None to a default value, e.g., \"unknown\" (if needed)\n",
    "trip_summary_df[\"start_location\"].fillna(\"None\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dd0eca-8273-4b84-80f6-a78cce4e7d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_summary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dfff39-14d4-43c1-b537-079e571311bd",
   "metadata": {},
   "source": [
    "#### Count the drives which started at home but ended somewhere else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca763f8-d4e5-4765-a476-7eeaed96c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count where start_location is \"home\" and end_location is None\n",
    "count_start_home_end_none = trip_summary_df[\n",
    "    (trip_summary_df[\"start_location\"] == \"home\") & \n",
    "    (trip_summary_df[\"end_location\"]!= \"home\")\n",
    "].drop_duplicates(subset=[\"subj\", \"drive\"]).shape[0]\n",
    "\n",
    "# Count where start_location is \"home\" and end_location is \"home\"\n",
    "count_start_home_end_home = trip_summary_df[\n",
    "    (trip_summary_df[\"start_location\"] == \"home\") & \n",
    "    (trip_summary_df[\"end_location\"] == \"home\")\n",
    "].drop_duplicates(subset=[\"subj\", \"drive\"]).shape[0]\n",
    "\n",
    "# Print results\n",
    "print(f\"Count of (start_location = home, end_location = None): {count_start_home_end_none}\")\n",
    "print(f\"Count of (start_location = home, end_location = home): {count_start_home_end_home}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f074a2d8-55d3-4e82-82a9-3160c5abe823",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trip_summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2e49e2-879b-4017-84b1-a9958b6b7e52",
   "metadata": {},
   "source": [
    "#### calculate time difference or stoppage between drives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726fda71-5a2c-4f51-9636-0d65cd4ac698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure the columns are datetime objects\n",
    "trip_summary_df[\"time_start_utc\"] = pd.to_datetime(trip_summary_df[\"time_start_utc\"])\n",
    "trip_summary_df[\"time_end_utc\"] = pd.to_datetime(trip_summary_df[\"time_end_utc\"])\n",
    "\n",
    "# Sort the DataFrame by subject and drive\n",
    "trip_summary_df = trip_summary_df.sort_values(by=[\"subj\", \"drive\"])\n",
    "\n",
    "# Define a function to compute time differences within groups\n",
    "def calculate_time_diff(group):\n",
    "    group = group.sort_values(by=\"drive\")  # Ensure drives are sorted\n",
    "    group[\"time_diff_minutes\"] = (\n",
    "        group[\"time_start_utc\"] - group[\"time_end_utc\"].shift(1)\n",
    "    ).dt.total_seconds() / 60\n",
    "    return group\n",
    "\n",
    "# Apply the function to each group and reset the index\n",
    "trip_summary_df = trip_summary_df.groupby(\"subj\", group_keys=False).apply(calculate_time_diff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94066e39-01cc-4e27-ad5f-a0544fe5a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_summary_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc988d2b-60d1-4b4b-abc1-2eb35d178b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where both start_location and end_location are \"home\"\n",
    "home_filter = (trip_summary_df[\"start_location\"] == \"home\") & (trip_summary_df[\"end_location\"] == \"home\")\n",
    "\n",
    "# Get the row with the minimum value of distance_miles\n",
    "min_distance_row = trip_summary_df.loc[home_filter, \"distance_miles\"].idxmin()\n",
    "\n",
    "# Get the row with the maximum value of distance_miles\n",
    "max_distance_row = trip_summary_df.loc[home_filter, \"distance_miles\"].idxmax()\n",
    "\n",
    "# Get the row with the minimum value of time_diff_minutes\n",
    "min_time_row = trip_summary_df.loc[home_filter, \"time_diff_minutes\"].idxmin()\n",
    "\n",
    "# Get the row with the maximum value of time_diff_minutes\n",
    "max_time_row = trip_summary_df.loc[home_filter, \"time_diff_minutes\"].idxmax()\n",
    "\n",
    "# Print the subj and drive information for these rows\n",
    "min_max_info = {\n",
    "    \"Min Distance Miles\": trip_summary_df.loc[min_distance_row, [\"subj\", \"drive\", \"distance_miles\"]],\n",
    "    \"Max Distance Miles\": trip_summary_df.loc[max_distance_row, [\"subj\", \"drive\", \"distance_miles\"]],\n",
    "    \"Min Time Diff\": trip_summary_df.loc[min_time_row, [\"subj\", \"drive\", \"time_diff_minutes\"]],\n",
    "    \"Max Time Diff\": trip_summary_df.loc[max_time_row, [\"subj\", \"drive\", \"time_diff_minutes\"]]\n",
    "}\n",
    "\n",
    "# Display the result\n",
    "for key, value in min_max_info.items():\n",
    "    print(f\"{key}: {value}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336b8f84-2cf6-4981-9996-99e5a0cebb74",
   "metadata": {},
   "source": [
    "#### calculate the trip chain information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da240b7f-5028-4ec1-b731-93d9d404dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure the DataFrame is sorted for sequential processing\n",
    "trip_summary_df = trip_summary_df.sort_values(by=[\"subj\", \"drive\"])\n",
    "\n",
    "# Initialize the `trip_chain` column\n",
    "trip_summary_df['trip_chain'] = None\n",
    "\n",
    "# Initialize global chain number\n",
    "global_chain_number = 0\n",
    "\n",
    "# Iterate over each unique subject\n",
    "for subj in trip_summary_df['subj'].unique():\n",
    "    # Filter trips for the current subject\n",
    "    subj_df = trip_summary_df[trip_summary_df['subj'] == subj]\n",
    "    \n",
    "    # Variables to track chain state\n",
    "    in_chain = False  # Flag for active chain\n",
    "    \n",
    "    for idx, row in subj_df.iterrows():\n",
    "        # Case 1: Standalone trips starting and ending at home\n",
    "        if row['start_location'] == 'home' and row['end_location'] == 'home':\n",
    "            global_chain_number += 1  # Increment global chain number\n",
    "            trip_summary_df.at[idx, 'trip_chain'] = global_chain_number  # Assign chain number\n",
    "            in_chain = False  # Reset chain flag\n",
    "\n",
    "        # Case 2: Trip starts at home but does not end at home\n",
    "        elif row['start_location'] == 'home' and row['end_location'] != 'home':\n",
    "            if not in_chain:  # Start a new chain if not already in one\n",
    "                global_chain_number += 1\n",
    "            trip_summary_df.at[idx, 'trip_chain'] = global_chain_number\n",
    "            in_chain = True  # Mark that we're in a chain\n",
    "\n",
    "        # Case 3: Trip does not start at home but ends at home\n",
    "        elif row['start_location'] != 'home' and row['end_location'] == 'home':\n",
    "            if in_chain:  # If already in a chain, continue it\n",
    "                trip_summary_df.at[idx, 'trip_chain'] = global_chain_number\n",
    "                in_chain = False  # End the chain\n",
    "\n",
    "        # Case 4: Other trips\n",
    "        else:\n",
    "            if in_chain:  # Continue the current chain\n",
    "                trip_summary_df.at[idx, 'trip_chain'] = global_chain_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b28055-63e4-410b-8e55-86e5d90a92b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e8823-6658-4ccd-a0bf-c191f8010835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered DataFrame to CSV\n",
    "#trip_summary_df.to_csv('trip_chain.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2e9419-7a37-41b4-a984-d044520653fb",
   "metadata": {},
   "source": [
    "### Take into account dwell time =30min to terminate the trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2dd3d9-fb04-484d-a425-65e1cafb46e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = '/Users/aparn/Box/InTrans/RWRAD_Internal/Final_files_with_variables/Trip_chain/trip_chain_v2.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "trip_summary_df= pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e37699d-77d6-493c-8623-ad6e1b000e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_summary_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9119b896-fafc-4969-9f0f-6dc76e0b5184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the specified columns into a new DataFrame\n",
    "trip_chain_check = trip_summary_df[['subj', 'drive', 'start_location', 'end_location', 'time_diff_minutes', 'trip_chain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6038ac9b-19e6-47ce-adef-9cfa33ba19ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a copy of the DataFrame\n",
    "updated_df = trip_summary_df.copy()\n",
    "\n",
    "# Identify 'trip_chain' values that appear more than once\n",
    "trip_chain_counts = updated_df['trip_chain'].value_counts()\n",
    "trip_chains_to_modify = trip_chain_counts[trip_chain_counts > 1].index\n",
    "\n",
    "# Iterate through the rows for trip chains with duplicates\n",
    "for trip_chain in trip_chains_to_modify:\n",
    "    # Get indices of rows corresponding to the current trip_chain\n",
    "    indices = updated_df[updated_df['trip_chain'] == trip_chain].index\n",
    "    # Set the 'time_diff_minutes' value to NaN for the first occurrence only\n",
    "    updated_df.loc[indices[0], 'time_diff_minutes'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c19061-2177-48a2-9750-e69edf965466",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba92495-feb3-4c35-881b-7d5e25777edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'trip_chain_check' as a copy of 'trip_chain'\n",
    "updated_df['trip_chain_check'] = updated_df['trip_chain']\n",
    "\n",
    "# Get the unique values of 'trip_chain' that appear more than once\n",
    "trip_chain_counts = updated_df['trip_chain'].value_counts()\n",
    "duplicate_trip_chains = trip_chain_counts[trip_chain_counts > 1].index\n",
    "\n",
    "# Iterate over duplicate trip chains and process 'time_diff_minutes'\n",
    "for trip_chain in duplicate_trip_chains:\n",
    "    # Filter rows for the current trip chain\n",
    "    rows = updated_df[updated_df['trip_chain'] == trip_chain]\n",
    "    \n",
    "    # Check if any 'time_diff_minutes' values are greater than 30 (ignore NaNs)\n",
    "    if rows['time_diff_minutes'].dropna().gt(30).any():\n",
    "        # Set 'trip_chain_check' for these rows to NaN\n",
    "        updated_df.loc[updated_df['trip_chain'] == trip_chain, 'trip_chain_check'] = np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc97e74-6792-4ede-b7c3-49183844e41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a706a25-d6b3-4691-a4bc-16b2a4de2287",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df['trip_chain_check'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eaa51f-a405-42f3-aa0e-cfc16a5be3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'trip_chain_check' column exists in updated_df\n",
    "if 'trip_chain_check' in updated_df.columns:\n",
    "    # Merge 'trip_chain_check' from updated_df into trip_summary_df based on keys\n",
    "    trip_summary_df = trip_summary_df.merge(\n",
    "        updated_df[['subj', 'drive', 'trip_chain', 'trip_chain_check']],\n",
    "        on=['subj', 'drive', 'trip_chain'],\n",
    "        how='left'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96051157-b52a-4c0a-8b8a-174b14489b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_summary_df['trip_chain_check'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc951c61-00d6-42ee-b59f-07a00a11ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered DataFrame to CSV\n",
    "#trip_summary_df.to_csv('trip_chain_dwell_time.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a6ed6-045c-4f14-8d0d-71a9cb07ad92",
   "metadata": {},
   "source": [
    "## correct 15miles 25miles from home variable (there are some more drives which start from home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7075a2d-92fc-41d0-9935-b1bcd3ac0ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'label' column wherever 'start_location' contains 'home'\n",
    "trip_summary_df.loc[trip_summary_df['start_location'].str.contains('home', case=False, na=False), 'label'] = 'home'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2cc4a8-86a3-45f4-8fd7-da64e1b9c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a new column '15_miles_from_home' where the distance is less than 15 miles and label is 'home'\n",
    "trip_summary_df['15_miles_from_home'] = trip_summary_df.apply(\n",
    "    lambda row: 'yes' if row['label'] == 'home' and row['distance_miles'] < 15 else ('no' if row['label'] == 'home' else np.nan), axis=1)\n",
    "\n",
    "# Create a new column '25_miles_from_home' where the distance is less than 25 miles and label is 'home'\n",
    "trip_summary_df['25_miles_from_home'] = trip_summary_df.apply(\n",
    "    lambda row: 'yes' if row['label'] == 'home' and row['distance_miles'] < 25 else ('no' if row['label'] == 'home' else np.nan), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d716f96-74c2-4783-b8c9-e753f9cf4d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered DataFrame to CSV\n",
    "trip_summary_df.to_csv('trip_chain_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db1dd4a-6d48-4be4-b327-06bac769b966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7333520-9573-4a47-9138-f24801255bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
