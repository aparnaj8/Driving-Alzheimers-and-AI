{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95961d25-aaf9-4064-8fec-2837e81487fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9dc8b1-d77f-4495-bb79-1315f8170256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44c7dca-554e-4c2c-a202-70cb96dcb04d",
   "metadata": {},
   "source": [
    "## Read file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23088351-77e8-4499-8274-84a704252831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = '/Users/aparnaj8/Box/InTrans/RWRAD_Internal/Final_files_with_variables/Trip_chain/trip_chain_dwell_time.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "trip_summary_df= pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e1bd68-f92f-4a51-af02-a85ec695e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_summary_df = trip_summary_df.drop(columns=['age'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb7fb8d-7e05-4240-9ce0-f107e955ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = '/Users/aparnaj8/Box/Data (Matthew Rizzo)/DataAnalysis/FormattingQAChecks/REDCap_Formatting/REDCap_Format_Data/demographics.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "demo_summary_df= pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a49b90d-54fc-42fb-81b0-f8bde0eb85d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_summary_df = demo_summary_df.rename(columns={'year': 'year_mapped'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d853cf-ff95-4fe0-903e-ce48fe409381",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d40a2-70eb-40c0-be08-f2b31b91788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path =  '/Users/aparnaj8/Box/InTrans/RWRAD_Internal/Final_files_with_variables/Speeding_Variable/high_speed_road_60mph_or_greater.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "high_speed_df= pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfa1579-d3a4-4119-a8f8-5513c4f88493",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_speed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b28cd1-479d-484d-8b9a-f7eb50b59d5f",
   "metadata": {},
   "source": [
    "### Merge files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93636831-25e3-4992-91e7-89262a3342dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df = trip_summary_df.merge(\n",
    "    demo_summary_df[['subj', 'year_mapped', 'education_years', 'race', 'gender', 'age']],  # Select required columns from demo_summary_df\n",
    "    on=['subj', 'year_mapped'],  # Merge on 'subj' and 'year_mapped' from both DataFrames\n",
    "    how='left'  # Retain all rows from trip_summary_df\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf0a240-2dff-42e1-b063-65c932a90f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f3d5b-7d61-4a83-8a67-7bc66f2f3834",
   "metadata": {},
   "source": [
    "#### AM PM peak variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36ab9e0-9935-4ee5-9d7b-e5026d16c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df['time_start_utc'] = pd.to_datetime(final_merged_df['time_start_utc'], errors='coerce')\n",
    "final_merged_df['time_end_utc'] = pd.to_datetime(final_merged_df['time_end_utc'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9954d2d-dd39-4b03-98f2-a57686c45912",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df['time_start_cst'] = pd.to_datetime(final_merged_df['time_start_cst'], errors='coerce')\n",
    "final_merged_df['time_end_cst'] = pd.to_datetime(final_merged_df['time_end_cst'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b352a23-0d43-4c1d-b347-a49a912ce026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def classify_time_of_day(timestamp):\n",
    "    hour = timestamp.hour\n",
    "    if 7 <= hour <= 9:\n",
    "        return 'AM Peak'\n",
    "    elif 16 <= hour <= 18:\n",
    "        return 'PM Peak'\n",
    "    else:\n",
    "        return 'None'\n",
    "\n",
    "# Example usage with a pandas dataframe\n",
    "final_merged_df['AM_PM_peak'] = final_merged_df['time_start_cst'].apply(lambda x: classify_time_of_day(pd.to_datetime(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfec57df-13d7-49f4-9936-9822bcdbb148",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2342fef8-052f-4edb-948b-97f81b51e7cf",
   "metadata": {},
   "source": [
    "### Nighttime Daytime trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa99be-fd3a-4a3d-98b4-3a77ca0b35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# Define nighttime period (9 PM to 6 AM)\n",
    "night_start = 21  # 9 PM\n",
    "night_end = 6     # 6 AM\n",
    "\n",
    "# Function to check if a specific time is nighttime\n",
    "def is_nighttime(timestamp):\n",
    "    hour = timestamp.hour\n",
    "    return night_start <= hour or hour < night_end\n",
    "\n",
    "# Function to calculate the percentage of the trip that is nighttime\n",
    "def calculate_nighttime_percentage(row):\n",
    "    # Convert start and end time to datetime\n",
    "    start_time = pd.to_datetime(row['time_start_cst'])\n",
    "    end_time = pd.to_datetime(row['time_end_cst'])\n",
    "\n",
    "    # Calculate the total trip duration in minutes\n",
    "    total_duration = (end_time - start_time).total_seconds() / 60  # in minutes\n",
    "\n",
    "    # Initialize counters for nighttime minutes\n",
    "    nighttime_minutes = 0\n",
    "\n",
    "    # Iterate through each minute of the trip\n",
    "    current_time = start_time\n",
    "    while current_time <= end_time:\n",
    "        if is_nighttime(current_time):\n",
    "            nighttime_minutes += 1\n",
    "        current_time += timedelta(minutes=1)\n",
    "\n",
    "    # Calculate the percentage of time that is nighttime\n",
    "    nighttime_percentage = (nighttime_minutes / total_duration) * 100\n",
    "    return nighttime_percentage\n",
    "\n",
    "# Apply the function to each row and assign \"nighttime\" or \"daytime\"\n",
    "final_merged_df['night_trips'] = final_merged_df.apply(calculate_nighttime_percentage, axis=1)\n",
    "\n",
    "# Create a new column 'day_or_night' based on the nighttime percentage\n",
    "final_merged_df['day_or_night'] = final_merged_df['night_trips'].apply(\n",
    "    lambda x: 'nighttime' if x >= 80 else 'daytime'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6161264-a5d9-4e8f-89b4-ad62539f1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40978768-f453-4091-97a7-0a3c25e9dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specified columns\n",
    "columns_to_drop = ['home_distance', 'label', 'trip_chain', 'time_diff_minutes', 'night_trips']\n",
    "final_merged_df = final_merged_df.drop(columns=columns_to_drop, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28929519-9b55-4276-ab8d-9fd834f6b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16caef8-0685-46ed-b32d-4f112b2dc7ca",
   "metadata": {},
   "source": [
    "## Correct within 15 and 25 miles frm home variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98945901-bcd0-4602-bdf3-80d1d732ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Add the '15_miles_from_home' column\n",
    "final_merged_df['15_miles_from_home'] = final_merged_df['distance_miles'].apply(lambda x: 'yes' if x <= 15 else 'no')\n",
    "\n",
    "# Add the '25_miles_from_home' column\n",
    "final_merged_df['25_miles_from_home'] = final_merged_df['distance_miles'].apply(lambda x: 'yes' if 15 < x <= 25 else 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a33d9e-2853-47ec-9ae5-d8294853fa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered DataFrame to CSV\n",
    "final_merged_df.to_csv('final_list_of_var_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39de3d6-6729-4aa3-ba16-b0a71dc292db",
   "metadata": {},
   "source": [
    "## Attach High Speed Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f144d9-1ed7-4536-a88c-2ad7f5aec4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge final_merged_df and high_speed_df on 'subj' and 'drive'\n",
    "final_high_speed= pd.merge(final_merged_df, high_speed_df, on=['subj', 'drive'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2242bbde-2e85-4ab6-ae0c-af7cecddd814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column\n",
    "final_high_speed.rename(columns={'percentage_at_60mph_or_greater': 'high_speed_drive'}, inplace=True)\n",
    "\n",
    "# Replace non-null values with 'Yes'\n",
    "final_high_speed['high_speed_drive'] = final_high_speed['high_speed_drive'].notnull().replace({True: 'Yes', False: None})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bfbf81-bc27-4af9-984a-1f32028f0b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_high_speed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67104c5e-9f18-4bff-9a95-6c1d3ee733c5",
   "metadata": {},
   "source": [
    "## Hard Braking information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f59a62-0c24-4657-96ed-e96268f7fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = r'C:/Users/aparnaj8/Box/InTrans/RWRAD_Internal/Final_files_with_variables/Hard_Braking/final_agg_hard_braking_3551.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "hard_brake_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b636cfc-595f-44e9-8d8c-2ea119a14934",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_brake_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41181a-9cda-4003-b26b-d63d22e352ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'subj' and 'drive', and count the occurrences of 'agg_hard_brake' for each combination\n",
    "hard_brake_counts = (\n",
    "    hard_brake_df.groupby(['subj', 'drive'])\n",
    "    .agg(count=('agg_hard_brake', 'count'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Store the result in a DataFrame for further merging\n",
    "hard_brake_counts_df = pd.DataFrame(hard_brake_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049cc83f-726a-49b6-bee4-cf4078d36736",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_brake_counts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb97c28-552c-4041-95a1-f9e805a7ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge final_high_speed and hard_brake_counts_df based on 'subj' and 'drive'\n",
    "merged_df = pd.merge(final_high_speed, hard_brake_counts_df, on=['subj', 'drive'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d08e98a-d124-4d37-971b-b5bc4115eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ea679f-086f-4327-b904-46c5c26942b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered DataFrame to CSV\n",
    "merged_df.to_csv('final_list_of_var_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59801c82-d678-47c0-8060-980fb7421cca",
   "metadata": {},
   "source": [
    "## Probability of stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bafad3-04c7-414c-84d9-43b2aeba7011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path =  r'C:/Users/aparnaj8/Box/InTrans/RWRAD_Internal/Final_files_with_variables/Final_list_of_variables/final_list_of_var_v2.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "list_of_var = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3574730d-7788-42e0-92f0-6d31dfe31fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path =  r'C:/Users/aparnaj8/Box/InTrans/RWRAD_Internal/Final_files_with_variables/Stopping_at_stop_sign/probability_of_stopping_final.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "stoppage_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7e04e3-bb36-485e-9d1f-603c0bf051c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0daae9b-c60d-4c29-a549-8f8dc705bf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the 'count' column\n",
    "list_of_var.rename(columns={'count': 'hard_brake_count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af410c2a-bb62-4ca0-8b8e-a4c2b065bdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoppage_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c9cbec-655b-427c-a20c-ee1cdc4d3808",
   "metadata": {},
   "source": [
    "## Attach probability of stopping for every subjec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6378c730-6a26-48c2-bf1b-17a566e8281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge based on 'subj' and 'week_number'\n",
    "final_df = pd.merge(list_of_var, stoppage_df, on=['subj', 'week_number'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74929216-f872-4504-a4b1-cfc11db69ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e0792-40de-4b46-932d-3fe42f0c9df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the specified columns from final_df\n",
    "final_df = final_df.drop(columns=['total_stop_signs', 'stoppages_yes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5510e63d-2930-42fe-a882-a2af08abd322",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d7f0a-f4e2-4319-8240-f0ee1b637ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131a4a2a-a73e-4cd5-9435-ee32d8c11af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure time_start_cst and time_end_cst are in datetime format\n",
    "final_df['time_start_cst'] = pd.to_datetime(final_df['time_start_cst'])\n",
    "final_df['time_end_cst'] = pd.to_datetime(final_df['time_end_cst'])\n",
    "\n",
    "# Calculate the duration in minutes\n",
    "final_df['calculated_minutes'] = (final_df['time_end_cst'] - final_df['time_start_cst']).dt.total_seconds() / 60\n",
    "\n",
    "# Update distance_minutes where it is NaN and distance_miles > 0\n",
    "condition = (final_df['duration_minutes'].isna()) & (final_df['distance_miles'] > 0)\n",
    "final_df.loc[condition, 'duration_minutes'] = final_df.loc[condition, 'calculated_minutes']\n",
    "\n",
    "# Drop the temporary 'calculated_minutes' column if it's no longer needed\n",
    "final_df.drop(columns=['calculated_minutes'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4519057-8d95-4c97-b1de-41df7bbb1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total NaN values in the entire DataFrame\n",
    "total_nan = final_df.isna().sum().sum()\n",
    "print(f\"Total NaN values in the DataFrame: {total_nan}\")\n",
    "\n",
    "# Count NaN values for each column\n",
    "nan_per_column = final_df.isna().sum()\n",
    "print(\"\\nNaN values per column:\")\n",
    "print(nan_per_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a331fb1-fd01-4199-b027-e0d4ec814d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered DataFrame to CSV\n",
    "final_df.to_csv('final_list_of_var_v3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3149dff-5d61-4ed6-acd6-5167336e3458",
   "metadata": {},
   "source": [
    "## Final cleaning and data addition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec77ca8-4d04-4659-a2a7-37a1e80cc4e2",
   "metadata": {},
   "source": [
    "#### remove nan from subj type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6160656a-a26d-442e-ace8-93e02d66a1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = '/Users/aparn/Box/InTrans/RWRAD_Internal/Final_files_with_variables/Final_list_of_variables/final_list_of_var_v3.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "final_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd35d1-bb63-45d1-af0d-ba1ff0cf9cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of NaN values in 'subj_type' column\n",
    "nan_count = final_df['subj_type'].isna().sum()\n",
    "\n",
    "print(f\"Number of NaN values in 'subj_type': {nan_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d8844-f1e2-4eda-aafe-c66391ac552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf778e3-937f-4d82-8971-0a5238af7f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['subj'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182e8805-20ed-430e-8c8f-aff89903ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'subj_type' is NaN\n",
    "final_df = final_df.dropna(subset=['subj_type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e754c3fb-f600-4e1d-b20b-243e83851a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b822ff-9535-4ce9-a03b-0552ab7ec700",
   "metadata": {},
   "source": [
    "### remove 2024 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e81578-3a6f-422a-9a1e-85cae0e36fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the rows where 'year' is 2024\n",
    "count_2024 = final_df[final_df['year'] == 2024].shape[0]\n",
    "\n",
    "# Display the count\n",
    "print(f\"Count of rows where year == 2024: {count_2024}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb6ae88-0426-496b-8a0c-3857c7517b0f",
   "metadata": {},
   "source": [
    "### attach acceleration infromation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ed7ffd-126a-48a6-b820-38efaf2dd153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path =  r'C:/Users/aparnaj8/Box/InTrans/RWRAD_Internal/Final_files_with_variables/average_accel_x_RWRAD.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "avg_accel = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ec5eda-008b-47bd-834b-08cc6f302d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675ac4a7-8b84-45e2-be55-a7844f2b05a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df1 = pd.merge(final_df, avg_accel, on=['subj', 'drive'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9853ff-8ac3-43a4-ada7-da3c4b7f92cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecea7618-e3d7-45b1-a538-1a7f096fd60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff9819b-bbf0-42fd-b850-b2f6db745173",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb056a5c-f74d-46b5-a1fe-6140c349c78a",
   "metadata": {},
   "source": [
    "## Extract final list of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ac6302-fe1f-4f4a-863c-e9f6d20e8e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_stats_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6d2a6a-8cfd-4d38-9568-67304fbc8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate all the required weekly statistics\n",
    "def calculate_weekly_stats(df):\n",
    "    # Convert 'time_start_utc' and 'time_end_utc' to datetime format if not already\n",
    "    df['time_start_utc'] = pd.to_datetime(df['time_start_utc'])\n",
    "    df['time_end_utc'] = pd.to_datetime(df['time_end_utc'])\n",
    "    df['time_start_cst'] = pd.to_datetime(df['time_start_cst'])\n",
    "    df['time_end_cst'] = pd.to_datetime(df['time_end_cst'])\n",
    "    \n",
    "    # Initialize an empty dictionary to store calculated values\n",
    "    weekly_stats = {}\n",
    "    \n",
    "    # Total number of miles driven in a week\n",
    "    weekly_stats['total_miles'] = df['distance_miles'].sum()\n",
    "\n",
    "    # Total number of trips in a week\n",
    "    weekly_stats['total_trips'] = df.shape[0]\n",
    "\n",
    "    # Total miles driven in a week divided by total number of trips in a week\n",
    "    weekly_stats['avg_miles_per_trip'] = weekly_stats['total_miles'] / weekly_stats['total_trips']\n",
    "\n",
    "    # Total driving minutes in a week\n",
    "    weekly_stats['total_minutes'] = df['duration_minutes'].sum()\n",
    "\n",
    "    # Total minutes of driving in a week divided by total number of trips in a week\n",
    "    weekly_stats['avg_minutes_per_trip'] = weekly_stats['total_minutes'] / weekly_stats['total_trips']\n",
    "\n",
    "    # Number of trips in week not classified as nighttime\n",
    "    weekly_stats['non_nighttime_trips'] = df[df['day_or_night'] != 'nighttime'].shape[0]\n",
    "\n",
    "    # Percent of trips in week not classified as nighttime\n",
    "    weekly_stats['percent_non_nighttime'] = (weekly_stats['non_nighttime_trips'] / weekly_stats['total_trips']) * 100\n",
    "\n",
    "    # Number of trips in week during 7–9 AM on weekdays\n",
    "    weekly_stats['am_7_9_trips'] = df[(df['AM_PM_peak'] == 'AM Peak')].shape[0]\n",
    "    \n",
    "    # Percent of trips in week during 7–9 AM on weekdays\n",
    "    weekly_stats['percent_am_7_9'] = (weekly_stats['am_7_9_trips'] / weekly_stats['total_trips']) * 100\n",
    "\n",
    "    # Number of trips during which at least 80% of a trip was during nighttime in week\n",
    "    weekly_stats['nighttime_80_percent'] = df[df['day_or_night'] == 'nighttime'].shape[0]\n",
    "\n",
    "    # Percent of trips during which at least 80% of a trip was during nighttime in week\n",
    "    weekly_stats['percent_nighttime_80'] = (weekly_stats['nighttime_80_percent'] / weekly_stats['total_trips']) * 100\n",
    "\n",
    "    # Number of trips in week during 4–6 PM on weekdays\n",
    "    weekly_stats['pm_4_6_trips'] = df[(df['AM_PM_peak'] == 'PM Peak')].shape[0]\n",
    "    \n",
    "    # Percent of trips in week during 4–6 PM on weekdays\n",
    "    weekly_stats['percent_pm_4_6'] = (weekly_stats['pm_4_6_trips'] / weekly_stats['total_trips']) * 100\n",
    "\n",
    "    # Number of trips traveled in week within 15 miles of home\n",
    "    weekly_stats['within_15_miles'] = df[df['15_miles_from_home'] == 'yes'].shape[0]\n",
    "\n",
    "    # Percent of trips traveled in week within 15 miles of home\n",
    "    weekly_stats['percent_within_15_miles'] = (weekly_stats['within_15_miles'] / weekly_stats['total_trips']) * 100\n",
    "\n",
    "    # Number of trips traveled in week within 25 miles of home\n",
    "    weekly_stats['within_25_miles'] = df[df['25_miles_from_home'] == 'yes'].shape[0]\n",
    "\n",
    "    # Percent of trips traveled in week within 25 miles of home\n",
    "    weekly_stats['percent_within_25_miles'] = (weekly_stats['within_25_miles'] / weekly_stats['total_trips']) * 100\n",
    "\n",
    "    # Number of trip chains in week (chain is a series of trips marked by unique values in 'trip_chain_check')\n",
    "    weekly_stats['trip_chains'] = df['trip_chain_check'].nunique()\n",
    "    \n",
    "    # Calculate the total miles driven for each trip chain\n",
    "    total_miles_chains = df.groupby('trip_chain_check')['distance_miles'].sum()\n",
    "    \n",
    "    # Calculate the total driving minutes for each trip chain\n",
    "    total_minutes_chains = df.groupby('trip_chain_check')['duration_minutes'].sum()\n",
    "    \n",
    "    # Calculate the total number of unique trip chains\n",
    "    total_trip_chains = df['trip_chain_check'].nunique()\n",
    "    \n",
    "    # Calculate the total miles of chains divided by the number of trip chains\n",
    "    avg_miles_per_chain = total_miles_chains.sum() / total_trip_chains if total_trip_chains != 0 else np.nan\n",
    "    \n",
    "    # Calculate the total driving minutes for chains divided by the number of trip chains\n",
    "    avg_minutes_per_chain = total_minutes_chains.sum() / total_trip_chains if total_trip_chains != 0 else np.nan\n",
    "    \n",
    "    # Add these to the weekly stats dictionary\n",
    "    weekly_stats['avg_miles_per_chain'] = avg_miles_per_chain\n",
    "    weekly_stats['avg_minutes_per_chain'] = avg_minutes_per_chain\n",
    "\n",
    "    # Make sure we only count 'Yes' and avoid NaN values\n",
    "    weekly_stats['speed_60_mph'] = df[df['high_speed_drive'] == 'Yes'].shape[0]\n",
    "    \n",
    "    # Percentage of trips in week where 20% of distance traveled was at a high-speed road\n",
    "    # If the total trips are non-zero, calculate percentage, else return NaN\n",
    "    weekly_stats['percent_speed_60_mph'] = (weekly_stats['speed_60_mph'] / weekly_stats['total_trips']) * 100 if weekly_stats['total_trips'] != 0 else np.nan\n",
    "\n",
    "    # The average speed of trips\n",
    "    weekly_stats['avg_trip_speed'] = df['speed_mph_mean'].mean()\n",
    "\n",
    "    # The average acceleration of trips\n",
    "    weekly_stats['avg_trip_accel_x'] = df['average_accel_x'].mean()\n",
    "    \n",
    "    # Number of events with a deceleration rate <= -0.35 g in a week\n",
    "    weekly_stats['hard_brake_events'] = df[df['hard_brake_count'] > 0].shape[0]\n",
    "\n",
    "    # Handling stoppage_probability: keeping unique values per subj\n",
    "    stoppage_values = df['stoppage_probability'].dropna().unique()\n",
    "    if len(stoppage_values) > 0:\n",
    "        weekly_stats['stoppage_probability'] = stoppage_values[0]  # Attach first unique value for subj\n",
    "\n",
    "    return weekly_stats\n",
    "\n",
    "# Group by subj, week_number, and year, then apply the calculation function\n",
    "weekly_stats_df = final_df1.groupby(['subj', 'week_number', 'year']).apply(calculate_weekly_stats).apply(pd.Series)\n",
    "\n",
    "# Reset index to ensure 'subj', 'week_number', and 'year' are in the columns\n",
    "weekly_stats_df.reset_index(inplace=True)\n",
    "\n",
    "# Fill NaNs in 'stoppage_probability' column with empty strings where no value exists\n",
    "weekly_stats_df['stoppage_probability'] = weekly_stats_df['stoppage_probability'].fillna('')\n",
    "\n",
    "# Ensure 'year' information is included in the final DataFrame\n",
    "\n",
    "# Reorder columns to have 'subj', 'week_number', and 'year' as the first three columns\n",
    "cols = ['subj', 'week_number', 'year'] + [col for col in weekly_stats_df.columns if col not in ['subj', 'week_number', 'year']]\n",
    "weekly_stats_df = weekly_stats_df[cols]\n",
    "\n",
    "\n",
    "# Reorder columns to have 'subj' and 'week_number' as the first two columns\n",
    "#cols = ['subj', 'week_number'] + [col for col in weekly_stats_df.columns if col not in ['subj', 'week_number']]\n",
    "#weekly_stats_df = weekly_stats_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274267c4-7461-4c40-ba33-beec3875263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14757e92-deac-40dd-8dee-f05a6ea688ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'subj' to get unique years for each subject\n",
    "multi_year_subj = final_df1.groupby('subj')['year'].nunique()\n",
    "\n",
    "# Filter subjects that have more than one unique year\n",
    "multi_year_subj = multi_year_subj[multi_year_subj > 1]\n",
    "\n",
    "# Display the subjects with more than one unique year\n",
    "print(multi_year_subj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e1b166-0af4-469c-aa5d-54be2b0b0734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for the subjects with more than one unique year\n",
    "filtered_data = final_df1[final_df1['subj'].isin(multi_year_subj.index)]\n",
    "\n",
    "# Group by 'subj' and check if 'subj_type' is consistent across years\n",
    "subj_type_changes = filtered_data.groupby('subj').agg({\n",
    "    'subj_type': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "# Filter subjects where 'subj_type' is changing (i.e., having more than 1 unique 'subj_type')\n",
    "changing_subj = subj_type_changes[subj_type_changes['subj_type'] > 1]\n",
    "\n",
    "# Display subjects where 'subj_type' is changing\n",
    "print(changing_subj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e72f6-2c7b-4909-9522-5ba7da565cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of final_df1 with additional columns\n",
    "additional_columns = ['education_years', 'race', 'gender', 'age', 'subj_type']\n",
    "final_df_subset = final_df1[['subj', 'year'] + additional_columns].drop_duplicates(subset=['subj', 'year'])\n",
    "\n",
    "# Merge the dataframes based on 'subj' and 'year'\n",
    "weekly_stats_df = weekly_stats_df.merge(final_df_subset, on=['subj', 'year'], how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72719a50-916d-4ce5-94af-36661efe8f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398c0a7-8079-4350-8141-ccfed52cf780",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weekly_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee0f9d8-20e3-40c3-a5b1-09b28437b0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final weekly statistics dataframe to a CSV file\n",
    "weekly_stats_df.to_csv('weekly_stats_with_demo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc79fc5-e00c-44f5-b8d9-421d4893ae53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a463ddd-99d1-47a7-ba3d-865cfdc297bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b777d8-7383-464c-b790-f1587c282cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa82cfe-76b9-4b16-9323-40bddd0678dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb570b-d614-4488-a13f-cf9366336f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
